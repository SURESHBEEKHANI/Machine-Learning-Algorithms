{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOhtXtMEW3szGYJUzMJr0cl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Machine-Learning-Regression-Algorithms-/blob/main/machine_learning_regression_algorithms_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqUqwG1912U7"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Importing NumPy for data manipulation operations\n",
        "import pandas as pd  # Importing Pandas to handle data in table-like structures\n",
        "\n",
        "# Setting up Matplotlib for plotting (data visualization)\n",
        "\n",
        "import matplotlib.pyplot as plt  # Importing Matplotlib's pyplot module for creating visual plots\n",
        "%matplotlib inline\n",
        "import seaborn as sns  # Importing Seaborn for advanced data visualization techniques\n",
        "\n",
        "import sklearn  # Importing scikit-learn for machine learning tasks\n",
        "\n",
        "import warnings  # Importing warnings library to handle warning messages\n",
        "warnings.filterwarnings('ignore')  # Ignoring all warning messages\n",
        "\n",
        "# Setting default plot size for visualizations\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "\n",
        "# Importing warnings library again (not necessary, already imported)\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)  # Ignoring future warnings\n",
        "\n",
        "# The following script is written to be easily understood by someone without a technical background from Pakistan.\n",
        "# Each line includes comments explaining its purpose in simple terms.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This line of code imports the read_csv function from the pandas library.\n",
        "# read_csv is a function that allows us to read data from a CSV (comma-separated values) file.\n",
        "# We're using it to load a dataset stored in a file named \"USA_Housing.csv\".\n",
        "# The data from the CSV file will be stored in a variable called 'data'.\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/USA_Housing.csv\")\n"
      ],
      "metadata": {
        "id": "lVW7wCIn8-CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line of code uses the shape function to display the dimensions of the dataset.\n",
        "# The shape function returns a tuple where the first element represents the number of rows and the second element represents the number of columns.\n",
        "# For example, if the shape of the dataset is (1000, 6), it means there are 1000 rows and 6 columns.\n",
        "data.shape\n"
      ],
      "metadata": {
        "id": "jesSEzzL-GBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line of code uses the head() function to display the first few rows of the dataset.\n",
        "# The head() function is very useful when you want to quickly look at a small part of your data.\n",
        "# By default, head() shows the first 5 rows, but you can specify a different number if you want.\n",
        "# For example, data.head(10) would show the first 10 rows instead of the first 5.\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "X3z6iQ779OqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line of code uses the info() function to get detailed information about the dataset.\n",
        "# The info() function provides a summary of the dataset, including the data types of each column and the number of non-null values.\n",
        "# It also shows if there are any missing values in the dataset.\n",
        "data.info()\n"
      ],
      "metadata": {
        "id": "SRQju0fI9gDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "Gzzk-DiONauD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We're removing the column labeled 'Address' from the data because\n",
        "#it's not needed for training the model.\n",
        "data.drop(columns='Address', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "W4IHOdT5Pf-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removed null values from the dataset\n",
        "data.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "5zL7rv53QHwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the describe() function to generate a summary of statistics, including the five-number summary (minimum, 25th percentile, median, 75th percentile, maximum) for each numerical column in the dataset.\n",
        "data.describe()\n"
      ],
      "metadata": {
        "id": "g0d1eMJqRtcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the final shape of the data before training the model\n",
        "data.shape\n",
        "\n",
        "# Train the model using the finalized data\n",
        "# Insert your model training code here\n"
      ],
      "metadata": {
        "id": "Pp8TYM-OSrIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the Features and Target Variable\n",
        "# Feature Representation: x represents the input variables\n",
        "# Target Variable Representation: y represents the output variable\n",
        "\n",
        "# Drop the 'Price' column from the DataFrame and assign the remaining data to variable x\n",
        "# This step selects the features (input variables) for our model\n",
        "x = data.drop('Price', axis=1)\n",
        "\n",
        "# Select the 'Price' column from the DataFrame and assign it to variable y\n",
        "# This step selects the target variable (output variable) for our model\n",
        "y = data['Price']\n"
      ],
      "metadata": {
        "id": "UDPH-AtlUY0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the feature data for training\n",
        "x.shape\n"
      ],
      "metadata": {
        "id": "BH3bBvNxWCnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the target variable for both training and testing data\n",
        "y.shape\n"
      ],
      "metadata": {
        "id": "cj72k3pyW2Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MinMaxScaler for feature scaling technique. This helps in adjusting the scale of features without changing their relationship.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the MinMaxScaler, which is a tool used to scale features to a specified range (usually between 0 and 1).\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply Min-Max scaling to your features (X). This step rescales the data so that each feature is within a specific range.\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# The variable x_scaled now contains the scaled features using Min-Max scaling. This ensures that all features have a consistent scale for better model performance.\n"
      ],
      "metadata": {
        "id": "j2LigzWuW6Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original values of x\n",
        "print(\"Original values of x:\")\n",
        "print(x)\n",
        "\n",
        "# Print the scaled values of x after Min-Max scaling\n",
        "print(\"\\nScaled values of x after Min-Max scaling:\")\n",
        "print(x_scaled)\n"
      ],
      "metadata": {
        "id": "AElLuJ0RXrAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "# Importing train_test_split function from sklearn library, which helps in splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the scaled features (x_scaled) and target variable (y) into training and testing sets\n",
        "# The test_size parameter specifies the proportion of the dataset to include in the testing set\n",
        "# Here, 10 samples will be used for testing\n",
        "# The random_state parameter ensures reproducibility of the split\n",
        "# It sets a seed for random number generation, so the same split can be reproduced if needed\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=10, random_state=101)\n"
      ],
      "metadata": {
        "id": "s4Fd609BoNm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vc6OP_qgpoF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the LinearRegression class from the scikit-learn library, which is used to create a linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize the linear regression model\n",
        "# This step creates an instance of the LinearRegression class, representing our linear regression model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# You can also specify additional parameters for the model if needed\n",
        "# For example, to fit the intercept, you can set fit_intercept=True:\n",
        "# This line fits the linear regression model to the training data\n",
        "linear_model.fit(x_train, y_train)\n",
        "\n",
        "# Now, the linear_model object represents your linear regression model\n",
        "# It can be used to fit the model to the training data and make predictions\n"
      ],
      "metadata": {
        "id": "VVVCwCXxrr8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting with the linear regression model\n",
        "# This line of code predicts the target variable (y) using the trained linear regression model (linear_model) and the test features (x_test)\n",
        "y_pred = linear_model.predict(x_test)\n",
        "\n",
        "# Printing the shape of the predicted values\n",
        "# This line prints the shape of the predicted values (y_pred), which indicates the number of predictions made\n",
        "print(y_pred.shape)\n",
        "\n",
        "# Printing the predicted values\n",
        "# This line prints the predicted values of the target variable (y) based on the test features (x_test)\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "bs4k0pvUv0Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the actual values vs. the predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', label=\"Actual data Point \")\n",
        "\n",
        "# Adding a line for perfect prediction (y = x)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', label='Ideal Line ')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Actual vs Predicted Values')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5FqVKPnCx5Zf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}